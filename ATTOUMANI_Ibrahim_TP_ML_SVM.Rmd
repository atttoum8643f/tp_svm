---
output: pdf_document
fontsize: 12pt
mainfont: "Times New Roman"
header-includes:
  - \usepackage{xcolor}
  - \usepackage{float}
  - \usepackage{colortbl}
  - \usepackage[table]{xcolor}
  - \usepackage{graphicx}
  - \usepackage{lscape}
  - \usepackage{tikz}
  - \usepackage{amsmath}
  - \usepackage{tcolorbox}
  - \usepackage{fancyhdr}
  - \usepackage{lipsum}
  - \setlength{\headheight}{15.35403pt}
  - \addtolength{\topmargin}{-2.5pt}
  - \pagestyle{fancy}
  - \fancyhead[L]{\textcolor{purple}{M2 SSD - BIOSTAT}}
  - \fancyhead[C]{\textcolor{purple}{Support Vector Machine \textbf{-} HAX907X}}
  - \fancyhead[R]{\textcolor{purple}{2025 \textbf{-} 2026}}
  - \fancyfoot[C]{\thepage}
  - \renewcommand{\contentsname}{Table des matières}
---

\begin{titlepage}
\definecolor{umcolor}{RGB}{85, 37, 130}

\begin{center}

% Logo en haut
\includegraphics[width=0.3\linewidth]{vis/logo/logo_m.png}\\[1.5cm]

% Université et département
{\Large \textsc{Université de Montpellier}}\\[0.2cm]
{\large Département de Mathématiques Appliquées}\\[1.5cm]

% Encadré du titre
\tcbset{colback=blue!20, colframe=red, width=\textwidth, arc=3mm, boxrule=0.8mm}
\begin{tcolorbox}
    \centering
    {\huge \bfseries TP3 : Support Vector Machine}\\[0.3cm]
    {\large \textit{Apprentissage Statistique — HAX907X}}
\end{tcolorbox}

\vfill

% Auteur
\begin{flushright}
    \textbf{Réalisé par :}\\
    ATTOUMANI Ibrahim
\end{flushright}

\vfill

% Bas de page
\includegraphics[width=0.25\linewidth]{vis/logo/ssd.png}\\[0.3cm]
{\Large Année Universitaire 2025 -- 2026}

\end{center}
\end{titlepage}

\thispagestyle{empty}
\definecolor{navy}{RGB}{11, 11, 69}
\definecolor{picker}{RGB}{235, 153, 30}

\newpage
\thispagestyle{empty}
\tableofcontents
\newpage

# \textcolor{red}{1. Introduction}

Les \textbf{SVM} (Support Vector Machines), introduits par Vapnik, sont des méthodes de classification très utilisées, en particulier pour la classification binaire. Elles reposent sur la recherche d’une règle de décision linéaire sous la forme d’un \textbf{hyperplan séparateur}. Pour traiter des problèmes plus complexes, cette recherche est effectuée non pas directement dans l’espace des données initiales, mais dans un \textbf{espace de caractéristiques} de grande dimension, obtenu grâce à une transformation non linéaire.

L’objectif de ce TP est d’appliquer les SVM sur des données réelles et simulées à l’aide de la librairie \texttt{scikit-learn} (qui s’appuie sur \texttt{libsvm}). Nous apprendrons également à ajuster les \textbf{hyperparamètres} et le \textbf{choix du noyau} afin de mieux contrôler la flexibilité du modèle.
\newpage


# \textcolor{red}{2. Classification sur les donnée Iris}

Dans cette section, nous allons mettre en œuvre un \textbf{SVM linéaire} afin de distinguer les classes \textbf{1 et 2} du jeu de données \textit{iris}. 
Pour simplifier le problème, seules les \textbf{deux premières variables} seront utilisées. 
Nous conserverons la moitié des données pour l'\textbf{apprentissage} et l'autre moitié pour le \textbf{test}, afin d'évaluer la capacité du modèle à bien généraliser.

## \textcolor{blue}{2.1. SVM linéaire : discrimination entre les classes 1 et 2 d’Iris}

Ici nous allons sélectionner les classes 1 et 2 du dataset \textit{iris}, puis conserver uniquement les deux premières variables (longueur et largeur des sépales) afin de simplifier la visualisation et la classification.


\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{vis/classif_90test_10train.png}
    \caption{SVM linéaire avec 90\% des données réservées au test}
    \label{fig:svm_iris_90test_10train}
\end{figure}


Ci-dessus, on a dédiées 90\% des données pour le test, ce qui ne laisse qu'environ 10\% pour l'entraînement (soit seulement 10 points). 
Avec si peu d'exemples, le SVM ne dispose pas d'assez d'informations pour bien apprendre. On a alors que la frontière de décision est très approximative et la précision sur le test chute à **0.48**, proche du hasard.


En utilisant 40\% des données pour le test, nous obtenons une précision de 7\%. Comparée à la **figure 1**, la frontière de décision sépare mieux les points, bien que quelques erreurs de prédiction subsistent. La **figure 2** ci-dessous illustre cette visualisation.


\begin{figure}[H]
    \centering
    \includegraphics[width=0.65\textwidth]{vis/classif_40test_60train.png}
    \caption{SVM linéaire avec 40\% des données réservées au test}
    \label{fig:svm_iris_40test_60train}
\end{figure}


## \textcolor{blue}{2.2. SVM polynomial : discrimination entre les classes 1 et 2 d’Iris}

Dans cette section, nous entraînons un SVM avec noyau polynomial pour discriminer les classes 1 et 2 d’Iris. Ce noyau permet de modéliser des frontières de décision non linéaires, plus flexibles que celles du SVM linéaire.  Nous comparerons ensuite ses performances et sa frontière de décision avec celles du SVM linéaire présenté précédemment.


\begin{figure}[H]
    \centering
    \includegraphics[width=0.65\textwidth]{vis/classif_poly_40test_60train.png}
    \caption{SVM polynomial avec 40\% des données réservées au test}
    \label{fig:svm_poly_iris_40test_60train}
\end{figure}

À présent, nous comparons la classification linéaire à la vclassification polynomiale. 
Cette dernière ajuste mieux la frontière de décision, avec une précision de 0.75 sur le jeu de test. 
Comme pour la classification linéaire, 40\% des données ont été utilisées pour l’évaluation.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.65\textwidth]{vis/classif_poly_90test_10train.png}
    \caption{SVM polynomial avec 90\% des données réservées au test}
    \label{fig:svm_poly_iris_90test_10train}
\end{figure}

Nous avons testé deux modèles SVM (linéaire et polynomial) sur les classes 1 et 2 de l’iris, en utilisant les caractéristiques \textit{sepal length} et \textit{sepal width}.  

Avec une grande proportion de données en test (90\%), les deux modèles donnent de faibles scores, mais le SVM polynomial s’adapte mieux grâce à une frontière de décision non linéaire.  

Avec une répartition plus équilibrée (60\% train / 40\% test), les performances s’améliorent. Le SVM polynomial reste légèrement meilleur, car il capture mieux la séparation non linéaire entre les classes.  

## \textcolor{blue}{2.3. SVM GUI: données simulées déséquilibré}

Cette application \textcolor{red}{svm\_gui.py}(\textcolor{blue}{https://scikit-learn.org/1.2/auto\_examples/applications/svm\_gui.html}) permet en temps réel d'évaluer l'impact du noyaux et du paramètre de régularisation $C$.

Dans ce qui suit, nous allons générer un jeu de données très déséquilibré avec beaucoup plus de points dans une classe que dans l'autre. Ensuite, nous utiliserons un noyau linéaire tout en réduisant le paramètre $C$ et observerons le résultat.


\newpage
# \textcolor{red}{Annexe}



\begin{thebibliography}{9}

\bibitem{scikit-learn}
scikit-learn developers.  
\textit{Support Vector Machines — scikit-learn documentation}.  
\url{http://scikit-learn.org/stable/modules/svm.html}.  
Consulté le 24 septembre 2025.

\bibitem{wiki-en}
Wikipedia.  
\textit{Support vector machine}.  
\url{http://en.wikipedia.org/wiki/Support_vector_machine}.  
Consulté le 24 septembre 2025.

\bibitem{wiki-fr}
Wikipédia.  
\textit{Machine à vecteurs de support}.  
\url{http://fr.wikipedia.org/wiki/Machine_%C3%A0_vecteurs_de_support}.  
Consulté le 24 septembre 2025.

\end{thebibliography}